{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Descriptive analysis for the manuscript\n",
    "\n",
    "Summarize geotagged tweets of the multiple regions used for the model experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% load_ext autoreload\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import scipy.stats as stats\n",
    "from  tqdm import tqdm\n",
    "import helpers as hp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def load_region_tweets(region=None):\n",
    "    df = pd.read_csv(f'../../dbs/{region}/geotweets.csv')\n",
    "    df['day'] = df['createdat'].apply(lambda x: x.split(' ')[0])\n",
    "    df['createdat'] = pd.to_datetime(df['createdat'], infer_datetime_format=True)\n",
    "    t_max, t_min = df.createdat.max(), df.createdat.min()\n",
    "    time_span = f'{t_min} - {t_max}'\n",
    "    num_users = len(df.userid.unique())\n",
    "    num_geo = len(df)\n",
    "    num_days = np.median(df.groupby(['userid'])['day'].nunique())\n",
    "    num_geo_freq = np.median(df.groupby(['userid']).size() / df.groupby(['userid'])['day'].nunique())\n",
    "    return region, time_span, num_users, num_geo, num_days, num_geo_freq\n",
    "\n",
    "def user_stats_cal(data):\n",
    "    time_span = data.createdat.max() - data.createdat.min()\n",
    "    time_span = time_span.days\n",
    "    if time_span == 0:\n",
    "        time_span += 1\n",
    "    num_days = data['day'].nunique()\n",
    "    num_geo = len(data)\n",
    "    geo_freq = num_geo / num_days\n",
    "    share_active = num_days / time_span\n",
    "    return pd.DataFrame.from_dict({'time_span': [time_span],\n",
    "            'num_days': [num_days],\n",
    "            'num_geo': [num_geo],\n",
    "            'geo_freq': [geo_freq],\n",
    "            'share_active': [share_active]\n",
    "            })\n",
    "\n",
    "def region_tweets_stats_per_user(region=None):\n",
    "    df = pd.read_csv(f'../../dbs/{region}/geotweets.csv')\n",
    "    df['day'] = df['createdat'].apply(lambda x: x.split(' ')[0])\n",
    "    df['createdat'] = pd.to_datetime(df['createdat'], infer_datetime_format=True)\n",
    "    tqdm.pandas(desc=region)\n",
    "    df_users = df.groupby('userid').progress_apply(user_stats_cal).reset_index()\n",
    "    df_users.loc[:, 'region'] = region\n",
    "    df_users.drop(columns=['level_1'], inplace=True)\n",
    "    return df_users\n",
    "\n",
    "region_list = ['sweden', 'netherlands', 'saopaulo']\n",
    "\n",
    "with open('../../lib/regions.yaml', encoding='utf8') as f:\n",
    "    region_manager = yaml.load(f, Loader=yaml.FullLoader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1 Summarize the geotagged tweets used as input to the model\n",
    "Geotagged tweets: Time span, No. of Twitter users, No. of geotagged tweets,\n",
    "Days covered/user, No. of geotagged tweets/day/user"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "              region                time_span  num_users  num_geo  num_days  \\\n0             Sweden  2010-09-15 - 2019-03-31       3961  1248158     111.0   \n1    The Netherlands  2010-09-12 - 2019-04-22       5375  1479674     100.0   \n2  São Paulo, Brazil  2010-09-15 - 2019-06-07      10943  3513796      96.0   \n\n   num_geo_freq  gdp_capita          country    pop  \n0      1.432292       54.61           Sweden  10.23  \n1      1.402878       53.02  The Netherlands  17.28  \n2      1.519231       27.13           Brazil  12.18  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>region</th>\n      <th>time_span</th>\n      <th>num_users</th>\n      <th>num_geo</th>\n      <th>num_days</th>\n      <th>num_geo_freq</th>\n      <th>gdp_capita</th>\n      <th>country</th>\n      <th>pop</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Sweden</td>\n      <td>2010-09-15 - 2019-03-31</td>\n      <td>3961</td>\n      <td>1248158</td>\n      <td>111.0</td>\n      <td>1.432292</td>\n      <td>54.61</td>\n      <td>Sweden</td>\n      <td>10.23</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The Netherlands</td>\n      <td>2010-09-12 - 2019-04-22</td>\n      <td>5375</td>\n      <td>1479674</td>\n      <td>100.0</td>\n      <td>1.402878</td>\n      <td>53.02</td>\n      <td>The Netherlands</td>\n      <td>17.28</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>São Paulo, Brazil</td>\n      <td>2010-09-15 - 2019-06-07</td>\n      <td>10943</td>\n      <td>3513796</td>\n      <td>96.0</td>\n      <td>1.519231</td>\n      <td>27.13</td>\n      <td>Brazil</td>\n      <td>12.18</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([load_region_tweets(region=x) for x in region_list],\n",
    "                  columns=('region', 'time_span', 'num_users', 'num_geo', 'num_days', 'num_geo_freq'))\n",
    "df.loc[:, 'gdp_capita'] = df.loc[:, 'region'].apply(lambda x: region_manager[x]['gdp_capita'])\n",
    "df.loc[:, 'country'] = df.loc[:, 'region'].apply(lambda x: region_manager[x]['country'])\n",
    "df.loc[:, 'pop'] = df.loc[:, 'region'].apply(lambda x: region_manager[x]['pop'])\n",
    "df.loc[:, 'time_span'] = df.loc[:, 'time_span'].apply(lambda x: ' - '.join([x_t.split(' ')[0] for x_t in x.split(' - ')]))\n",
    "df.loc[:, 'region'] = df.loc[:, 'region'].apply(lambda x: region_manager[x]['name'])\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.to_clipboard(index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2 Merge ODMs for visualisation\n",
    "This part applies to Sweden, The Netherlands, and Sao Paulo, Brazil.\n",
    "\n",
    "Separate files will be deleted."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "for region in ['sweden', 'netherlands', 'saopaulo']:\n",
    "    df = pd.read_csv(f'../../dbs/{region}/odm_gt.csv')\n",
    "    df_c = pd.read_csv(f'../../dbs/{region}/odm_calibration.csv')\n",
    "    df_v = pd.read_csv(f'../../dbs/{region}/odm_validation.csv')\n",
    "    df_cb = pd.read_csv(f'../../dbs/{region}/odm_benchmark_c.csv')\n",
    "    df_vb = pd.read_csv(f'../../dbs/{region}/odm_benchmark_v.csv')\n",
    "    df = pd.merge(df, df_c, on=['ozone', 'dzone'])\n",
    "    df = df.rename(columns={'model': 'model_c'})\n",
    "    df = pd.merge(df, df_v, on=['ozone', 'dzone'])\n",
    "    df = df.rename(columns={'model': 'model_v'})\n",
    "    df = pd.merge(df, df_cb, on=['ozone', 'dzone'])\n",
    "    df = df.rename(columns={'benchmark': 'benchmark_c'})\n",
    "    df = pd.merge(df, df_vb, on=['ozone', 'dzone'])\n",
    "    df = df.rename(columns={'benchmark': 'benchmark_v'})\n",
    "    df.loc[:, ['ozone', 'dzone',\n",
    "               'gt', 'model_c', 'model_v',\n",
    "               'benchmark_c', 'benchmark_v']].to_csv(f'../../dbs/{region}/odms.csv', index=False)\n",
    "    os.remove(f'../../dbs/{region}/odm_gt.csv')\n",
    "    os.remove(f'../../dbs/{region}/odm_calibration.csv')\n",
    "    os.remove(f'../../dbs/{region}/odm_validation.csv')\n",
    "    os.remove(f'../../dbs/{region}/odm_benchmark_c.csv')\n",
    "    os.remove(f'../../dbs/{region}/odm_benchmark_v.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3 Quantify the od-pair similarity\n",
    "This part applies to Sweden, The Netherlands, and Sao Paulo, Brazil.\n",
    "\n",
    "The overall similarity."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "         region       type data       cor              p       ssi\n0        sweden      model    c  0.187270  6.653740e-246  0.301279\n1        sweden  benchmark    c  0.220507  9.577697e-277  0.301584\n2        sweden      model    v  0.184070  2.009274e-128  0.311876\n3        sweden  benchmark    v  0.266851  3.416318e-215  0.327934\n4   netherlands      model    c  0.439008   0.000000e+00  0.431704\n5   netherlands  benchmark    c  0.331307   0.000000e+00  0.391578\n6   netherlands      model    v  0.432798   0.000000e+00  0.432729\n7   netherlands  benchmark    v  0.404650   0.000000e+00  0.387912\n8      saopaulo      model    c  0.414933   0.000000e+00  0.510122\n9      saopaulo  benchmark    c  0.296695   0.000000e+00  0.446349\n10     saopaulo      model    v  0.480378   0.000000e+00  0.576264\n11     saopaulo  benchmark    v  0.356082   0.000000e+00  0.454928",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>region</th>\n      <th>type</th>\n      <th>data</th>\n      <th>cor</th>\n      <th>p</th>\n      <th>ssi</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>sweden</td>\n      <td>model</td>\n      <td>c</td>\n      <td>0.187270</td>\n      <td>6.653740e-246</td>\n      <td>0.301279</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>sweden</td>\n      <td>benchmark</td>\n      <td>c</td>\n      <td>0.220507</td>\n      <td>9.577697e-277</td>\n      <td>0.301584</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>sweden</td>\n      <td>model</td>\n      <td>v</td>\n      <td>0.184070</td>\n      <td>2.009274e-128</td>\n      <td>0.311876</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>sweden</td>\n      <td>benchmark</td>\n      <td>v</td>\n      <td>0.266851</td>\n      <td>3.416318e-215</td>\n      <td>0.327934</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>netherlands</td>\n      <td>model</td>\n      <td>c</td>\n      <td>0.439008</td>\n      <td>0.000000e+00</td>\n      <td>0.431704</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>netherlands</td>\n      <td>benchmark</td>\n      <td>c</td>\n      <td>0.331307</td>\n      <td>0.000000e+00</td>\n      <td>0.391578</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>netherlands</td>\n      <td>model</td>\n      <td>v</td>\n      <td>0.432798</td>\n      <td>0.000000e+00</td>\n      <td>0.432729</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>netherlands</td>\n      <td>benchmark</td>\n      <td>v</td>\n      <td>0.404650</td>\n      <td>0.000000e+00</td>\n      <td>0.387912</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>saopaulo</td>\n      <td>model</td>\n      <td>c</td>\n      <td>0.414933</td>\n      <td>0.000000e+00</td>\n      <td>0.510122</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>saopaulo</td>\n      <td>benchmark</td>\n      <td>c</td>\n      <td>0.296695</td>\n      <td>0.000000e+00</td>\n      <td>0.446349</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>saopaulo</td>\n      <td>model</td>\n      <td>v</td>\n      <td>0.480378</td>\n      <td>0.000000e+00</td>\n      <td>0.576264</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>saopaulo</td>\n      <td>benchmark</td>\n      <td>v</td>\n      <td>0.356082</td>\n      <td>0.000000e+00</td>\n      <td>0.454928</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quant_list = []\n",
    "for region in ['sweden', 'netherlands', 'saopaulo']:\n",
    "    df = pd.read_csv(f'../../dbs/{region}/odms.csv')\n",
    "    df_c = df.loc[(df.gt != 0) & (df.model_c != 0) & (df.benchmark_c != 0), :]\n",
    "    mc = stats.kendalltau(df_c.loc[:, 'gt'], df_c.loc[:, 'model_c'])\n",
    "    quant_list.append((region, 'model', 'c', mc.correlation, mc.pvalue, hp.ssi_dataframe(df, 'gt', 'model_c')))\n",
    "\n",
    "    bc = stats.kendalltau(df_c.loc[:, 'gt'], df_c.loc[:, 'benchmark_c'])\n",
    "    quant_list.append((region, 'benchmark', 'c', bc.correlation, bc.pvalue, hp.ssi_dataframe(df, 'gt', 'benchmark_c')))\n",
    "\n",
    "    df_v = df.loc[(df.gt != 0) & (df.model_v != 0) & (df.benchmark_v != 0), :]\n",
    "    mv = stats.kendalltau(df_v.loc[:, 'gt'], df_v.loc[:, 'model_v'])\n",
    "    quant_list.append((region, 'model', 'v', mv.correlation, mv.pvalue, hp.ssi_dataframe(df, 'gt', 'model_v')))\n",
    "\n",
    "    bv = stats.kendalltau(df_v.loc[:, 'gt'], df_v.loc[:, 'benchmark_v'])\n",
    "    quant_list.append((region, 'benchmark', 'v', bv.correlation, bv.pvalue, hp.ssi_dataframe(df, 'gt', 'benchmark_v')))\n",
    "df_stats = pd.DataFrame(quant_list, columns=['region', 'type', 'data', 'cor', 'p', 'ssi'])\n",
    "df_stats"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": "                            cor       ssi\nregion      type                         \nnetherlands benchmark  0.367978  0.389745\n            model      0.435903  0.432216\nsaopaulo    benchmark  0.326389  0.450639\n            model      0.447656  0.543193\nsweden      benchmark  0.243679  0.314759\n            model      0.185670  0.306577",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>cor</th>\n      <th>ssi</th>\n    </tr>\n    <tr>\n      <th>region</th>\n      <th>type</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">netherlands</th>\n      <th>benchmark</th>\n      <td>0.367978</td>\n      <td>0.389745</td>\n    </tr>\n    <tr>\n      <th>model</th>\n      <td>0.435903</td>\n      <td>0.432216</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">saopaulo</th>\n      <th>benchmark</th>\n      <td>0.326389</td>\n      <td>0.450639</td>\n    </tr>\n    <tr>\n      <th>model</th>\n      <td>0.447656</td>\n      <td>0.543193</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">sweden</th>\n      <th>benchmark</th>\n      <td>0.243679</td>\n      <td>0.314759</td>\n    </tr>\n    <tr>\n      <th>model</th>\n      <td>0.185670</td>\n      <td>0.306577</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stats.groupby(['region', 'type'])['cor', 'ssi'].mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "stats_av = df_stats.groupby(['region', 'type'])['cor', 'ssi'].mean().reset_index()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "pd.pivot_table(stats_av, index='region', columns=['type'], values=['cor', 'ssi']).to_clipboard()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}